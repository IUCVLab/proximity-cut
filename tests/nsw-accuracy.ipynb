{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os.path\n",
    "\n",
    "sys.path.append('../modules')\n",
    "from nsw import Node, NSWGraph\n",
    "from nsw_visualization import show_state\n",
    "import data_gen as dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_searcher(leader, cloud):\n",
    "    subset = data[np.array(cloud)[:,1].astype(int),:]\n",
    "    clear_output(wait=True)\n",
    "    show_state(data, subset, leader=leader.reshape(1, -1), target=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "grid = {\n",
    "    \"size\": [2000, 10000, 100000],\n",
    "    \"dim\": [2, 5, 10, 50, 100],\n",
    "    \"regularity_ratio\": [1, 2, 5, 10],\n",
    "    \"multisearch\": [5, 10, 20],\n",
    "    \"top\": [10, 100, 1000]\n",
    "}\n",
    "\n",
    "test_size = 100\n",
    "approx_constant = 10\n",
    "\n",
    "times_build = {}\n",
    "times_search = {}\n",
    "accuracy = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset for 2000 samples with 2 dimensions generated\n",
      "Data with labels is created\n",
      "Ground truth is generated\n",
      "Graph [K=8, Repeat=5] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 5.23% ; scaled[10] ~ 5.30%\n",
      "top 1000 ~ 21.82% ; scaled[10] ~ 26.68%\n",
      "Graph [K=16, Repeat=5] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 4.75% ; scaled[10] ~ 4.80%\n",
      "top 1000 ~ 28.33% ; scaled[10] ~ 32.99%\n",
      "Graph [K=39, Repeat=5] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 4.61% ; scaled[10] ~ 4.70%\n",
      "top 1000 ~ 41.88% ; scaled[10] ~ 44.98%\n",
      "Graph [K=77, Repeat=5] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 5.00% ; scaled[10] ~ 5.20%\n",
      "top 1000 ~ 48.22% ; scaled[10] ~ 47.39%\n",
      "Graph [K=8, Repeat=10] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 4.81% ; scaled[10] ~ 4.60%\n",
      "top 1000 ~ 32.82% ; scaled[10] ~ 36.25%\n",
      "Graph [K=16, Repeat=10] is loaded from file.\n",
      "top 10 ~ 0.30% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 4.73% ; scaled[10] ~ 4.90%\n",
      "top 1000 ~ 42.64% ; scaled[10] ~ 44.35%\n",
      "Graph [K=39, Repeat=10] is generated in 318.82 sec.\n",
      "top 10 ~ 0.10% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 2.74% ; scaled[10] ~ 2.40%\n",
      "top 1000 ~ 45.25% ; scaled[10] ~ 37.77%\n",
      "Graph [K=77, Repeat=10] is generated in 476.17 sec.\n",
      "top 10 ~ 0.10% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 2.84% ; scaled[10] ~ 2.20%\n",
      "top 1000 ~ 42.19% ; scaled[10] ~ 31.15%\n",
      "Graph [K=8, Repeat=20] is generated in 144.83 sec.\n",
      "top 10 ~ 0.10% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 2.29% ; scaled[10] ~ 2.70%\n",
      "top 1000 ~ 43.67% ; scaled[10] ~ 40.80%\n",
      "Graph [K=16, Repeat=20] is generated in 341.83 sec.\n",
      "top 10 ~ 0.10% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 2.59% ; scaled[10] ~ 2.30%\n",
      "top 1000 ~ 44.59% ; scaled[10] ~ 37.29%\n",
      "Graph [K=39, Repeat=20] is generated in 603.95 sec.\n",
      "top 10 ~ 0.10% ; scaled[10] ~ 0.00%\n",
      "top 100 ~ 2.84% ; scaled[10] ~ 2.20%\n",
      "top 1000 ~ 42.13% ; scaled[10] ~ 31.17%\n"
     ]
    }
   ],
   "source": [
    "for dim in grid[\"dim\"]:\n",
    "    for size in grid[\"size\"]:\n",
    "        data = np.random.rand(size, dim)\n",
    "        test = np.random.rand(test_size, dim)\n",
    "        print(f\"Dataset for {size} samples with {dim} dimensions generated\")\n",
    "        data_with_classes = list((row, 0) for row in data)\n",
    "        print(\"Data with labels is created\")\n",
    "        \n",
    "        dist = data @ test.T\n",
    "        \n",
    "        # for each test sample\n",
    "        closest = []\n",
    "        for i in range(test.shape[0]):\n",
    "            cl = np.argpartition(dist[:, i], max(grid[\"top\"])).tolist()\n",
    "            closest.append(cl)\n",
    "        print(\"Ground truth is generated\")\n",
    "        \n",
    "        for multisearch in grid[\"multisearch\"]:\n",
    "            for regularity_ratio in grid[\"regularity_ratio\"]:\n",
    "                regularity = math.ceil(math.log(size) * regularity_ratio)\n",
    "\n",
    "                tpl = (dim, size, regularity, multisearch) \n",
    "                \n",
    "                filename = f\"../dumps/{dim}D_{size}items_{regularity}regular_{multisearch}repeat.graph\"\n",
    "                if os.path.exists(filename):\n",
    "                    G = NSWGraph.load(filename)\n",
    "                    print(f\"Graph [K={regularity}, Repeat={multisearch}] is loaded from file.\")\n",
    "                else:\n",
    "                    start = time.time()\n",
    "                    G = NSWGraph()\n",
    "                    G.build_navigable_graph(data_with_classes,  K=regularity, attempts=multisearch)\n",
    "                    fin = time.time()\n",
    "                    t = fin - start\n",
    "                    G.save(filename)\n",
    "                    print(f\"Graph [K={regularity}, Repeat={multisearch}] is generated in {t:.2f} sec.\")\n",
    "                    times_build[tpl] = t\n",
    "                \n",
    "                for top in grid[\"top\"]:\n",
    "                    tpl = (dim, size, regularity, multisearch, top)                 \n",
    "                    match, match_scaled, total, total_scaled = 0, 0, 0, 0\n",
    "                    for i, row in enumerate(test):\n",
    "                        start += time.time()\n",
    "                        result = G.multi_search(row, attempts=multisearch, top=top)\n",
    "                        fin += time.time()\n",
    "                        \n",
    "                        result = set(result)\n",
    "                        intersect = len(result.intersection(closest[i][:top]))\n",
    "                        intersect_scaled = len(result.intersection(closest[i][:top // approx_constant]))\n",
    "                        match += intersect\n",
    "                        match_scaled += intersect_scaled\n",
    "                        total += top\n",
    "                        total_scaled += top // approx_constant\n",
    "                    accuracy[tpl] = (match, total)\n",
    "                    print(f'top {top} ~ {100 * match / total:.2f}% ; scaled[{approx_constant}] ~ {100 * match_scaled / total_scaled:.2f}%')\n",
    "                    times_search[tpl] = (fin - start) / test.shape[0] "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
