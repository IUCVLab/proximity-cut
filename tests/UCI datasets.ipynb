{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "sys.path.append('../modules')\n",
    "import requests\n",
    "from nsw.nsw_classifier import NSWClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(dataset):\n",
    "    summ = [0] * len(dataset[0][0])\n",
    "    for i in range(len(dataset[0][0])):\n",
    "        if type(dataset[0][0][i]) != float:\n",
    "            summ[i] = None\n",
    "    std = list(summ)\n",
    "    \n",
    "    # summ\n",
    "    for row in dataset:\n",
    "        for i in range(len(summ)):\n",
    "            if summ[i] is not None: \n",
    "                summ[i] += row[0][i]\n",
    "    \n",
    "    # avg\n",
    "    for i in range(len(summ)):\n",
    "        if summ[i] is not None: \n",
    "            summ[i] /= len(dataset)\n",
    "    \n",
    "    # std\n",
    "    for row in dataset:\n",
    "        for i in range(len(summ)):\n",
    "            if summ[i] is not None: \n",
    "                std[i] += (summ[i] - row[0][i]) ** 2\n",
    "    \n",
    "    for i in range(len(summ)):\n",
    "        if summ[i] is not None: \n",
    "            std[i] += (std[i] / (len(dataset) - 1)) ** .5\n",
    "\n",
    "    for row in dataset:\n",
    "        for i in range(len(summ)):\n",
    "            if summ[i] is not None: \n",
    "                if std[i] != 0.0:\n",
    "                    row[0][i] = (row[0][i] - summ[i]) / (4 * std[i])\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download (requires manual call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.abspath(\"../data/isolet\")\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    prefix = \"https://archive.ics.uci.edu/ml/machine-learning-databases/isolet/\"\n",
    "    for file in [\"isolet.info\", \"isolet.names\", \"isolet1+2+3+4.data.Z\", \"isolet5.data.Z\"]:\n",
    "        url = prefix + file\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(folder + \"/\" + file, 'wb').write(r.content)\n",
    "    \n",
    "    # you can do this manually is you don't have 7zip\n",
    "    exe7z = \"C:/Program Files/7-Zip/7z.exe\"\n",
    "    for file in [\"isolet1+2+3+4.data.Z\", \"isolet5.data.Z\"]:\n",
    "        exe = f\"\\\"{exe7z}\\\" e -o\\\"{folder}\\\" \\\"{folder}/{file}\\\"\"\n",
    "        print(exe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename):\n",
    "    result = []\n",
    "    for line in open(filename, 'r'):\n",
    "        parts = line.split(',')\n",
    "        cls = int(float(parts[-1]))\n",
    "        vector = [float(v) for v in parts[:-1]]\n",
    "        result.append((vector, cls))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(folder + \"/isolet1+2+3+4.data\")\n",
    "test = load_data(folder + \"/isolet5.data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test sparse graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier graph is build in 92.383s\n",
      "Classifier graph is build in 189.845s\n",
      "Classifier graph is build in 342.232s\n"
     ]
    }
   ],
   "source": [
    "G8, G16, G32 = NSWClassifier(), NSWClassifier(), NSWClassifier()\n",
    "G8.build_navigable_graph(train, attempts=1, M=8)\n",
    "G16.build_navigable_graph(train, attempts=1, M=16)\n",
    "G32.build_navigable_graph(train, attempts=1, M=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P8\tP16\tP32\tK8\tK16\tK32\n",
      "648\t979\t1293\t1244\t1348\t1403\t1559\n",
      "0.416\t0.628\t0.829\t0.798\t0.865\t0.900\n"
     ]
    }
   ],
   "source": [
    "path8 = 0\n",
    "path16 = 0\n",
    "path32 = 0\n",
    "knn8 = 0\n",
    "knn16 = 0\n",
    "knn32 = 0\n",
    "for t in test:\n",
    "    path8 += G8.classify_by_path(t[0], attempts=7) == t[1]\n",
    "    path16 += G16.classify_by_path(t[0], attempts=7) == t[1]\n",
    "    path32 += G32.classify_by_path(t[0], attempts=7) == t[1]\n",
    "    knn8 += G8.classify_knn(t[0], k=7) == t[1]\n",
    "    knn16 += G16.classify_knn(t[0], k=7) == t[1]\n",
    "    knn32 += G32.classify_knn(t[0], k=7) == t[1]\n",
    "print(f\"P8\\tP16\\tP32\\tK8\\tK16\\tK32\")\n",
    "print(f\"{path8}\\t{path16}\\t{path32}\\t{knn8}\\t{knn16}\\t{knn32}\\t{len(test)}\")\n",
    "print(f\"{path8 / len(test):.3f}\\t{path16 / len(test):.3f}\\t{path32 / len(test):.3f}\\t{knn8 / len(test):.3f}\\t{knn16 / len(test):.3f}\\t{knn32 / len(test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test medium graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier graph is build in 644.523s\n",
      "1369 1409\n"
     ]
    }
   ],
   "source": [
    "G64 = NSWClassifier()\n",
    "G64.build_navigable_graph(train, attempts=1, M=64)\n",
    "knn64 = 0\n",
    "path64 = 0\n",
    "for t in test:\n",
    "    path64 += G64.classify_by_path(t[0], attempts=7) == t[1]\n",
    "    knn64 += G64.classify_knn(t[0], k=7) == t[1]\n",
    "    \n",
    "print(path64, knn64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier graph is build in 1041.164s\n",
      "1380 1410\n",
      "0.8851828094932649 0.9044259140474663\n"
     ]
    }
   ],
   "source": [
    "G128 = NSWClassifier()\n",
    "G128.build_navigaget_hvdmraph(train, attempts=1, M=128)\n",
    "knn128 = 0\n",
    "path128 = 0\n",
    "for t in test:\n",
    "    path128 += G128.classify_by_path(t[0], attempts=7) == t[1]\n",
    "    knn128 += G128.classify_knn(t[0], k=7) == t[1]\n",
    "    \n",
    "print(path128, knn128)\n",
    "print(path128 / len(test), knn128 / len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dermatology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.abspath(\"../data/dermatology\")\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    prefix = \"https://archive.ics.uci.edu/ml/machine-learning-databases/dermatology/\"\n",
    "    for file in [\"dermatology.data\"]:\n",
    "        url = prefix + file\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(folder + \"/\" + file, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_derm_data(filename):\n",
    "    result = []\n",
    "    mx = 0\n",
    "    for line in open(filename, 'r'):\n",
    "        parts = line.split(',')\n",
    "        cls = int(float(parts[-1]))\n",
    "        vector = parts[:-1]\n",
    "        if vector[-1] != '?':\n",
    "            vector[-1] = int(vector[-1])\n",
    "            mx = max(vector[-1], mx)\n",
    "        result.append((vector, cls))\n",
    "    for row in result:\n",
    "        if row[0][-1] == '?':\n",
    "            row[0][-1] = .5\n",
    "        else:\n",
    "            row[0][-1] /= mx;\n",
    "    \n",
    "    return result   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train/test and distance function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "dataset = norm(load_derm_data(folder + \"/dermatology.data\"))\n",
    "random.seed(13)\n",
    "random.shuffle(dataset)\n",
    "\n",
    "train_derm, test_derm = dataset[:320], dataset[320:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size=320, dim=34, classes={1, 2, 3, 4, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "from tools.hvdm import get_hvdm\n",
    "dist_derm = get_hvdm(train_derm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier graph is build in 1.991s\n",
      "Path\t11-NN\n",
      "44\t45\n",
      "0.957, 0.978\n"
     ]
    }
   ],
   "source": [
    "cderm = NSWClassifier(dist=dist_derm)\n",
    "cderm.build_navigable_graph(train_derm, attempts=2, M=100)\n",
    "knn_derm = 0\n",
    "path_derm = 0\n",
    "for t in test_derm:\n",
    "    path_derm += cderm.classify_by_path(t[0], attempts=10) == t[1]\n",
    "    knn_derm += cderm.classify_knn(t[0], k=10) == t[1]\n",
    "    \n",
    "print(\"Path\\t11-NN\")\n",
    "print(f\"{path_derm}\\t{knn_derm}\")\n",
    "print(f\"{path_derm / len(test_derm):.3f}, {knn_derm / len(test_derm):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = os.path.abspath(\"../data/segmentation\")\n",
    "if not os.path.exists(folder):\n",
    "    os.mkdir(folder)\n",
    "    prefix = \"https://archive.ics.uci.edu/ml/machine-learning-databases/image/\"\n",
    "    for file in [\"segmentation.data\", \"segmentation.test\"]:\n",
    "        url = prefix + file\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(folder + \"/\" + file, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segment_data(filename):\n",
    "    result = []\n",
    "    for i, line in enumerate(open(filename, 'r')):\n",
    "        if i < 5: continue\n",
    "        parts = line.split(',')\n",
    "        cls = parts[0]\n",
    "        vector = [float(v) for v in parts[1:]]\n",
    "        result.append((vector, cls))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210 2100\n"
     ]
    }
   ],
   "source": [
    "## can be swapped, as \".test\" holds 2100 lines and '.data' - 210\n",
    "train_segm = (load_segment_data(folder + \"/segmentation.data\"))\n",
    "test_segm = (load_segment_data(folder + \"/segmentation.test\"))\n",
    "print(len(train_segm), len(test_segm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier graph is build in 1.055s\n",
      "Path\t1-NN\n",
      "1834\t1837\n",
      "0.873, 0.875\n"
     ]
    }
   ],
   "source": [
    "segment_clf = NSWClassifier()\n",
    "segment_clf.build_navigable_graph(train_segm, attempts=2, M=50)\n",
    "knn_segm = 0\n",
    "path_segm = 0\n",
    "for t in test_segm:\n",
    "    path_segm += segment_clf.classify_by_path(t[0], attempts=1) == t[1]\n",
    "    knn_segm += segment_clf.classify_knn(t[0], k=1) == t[1]\n",
    "    \n",
    "print(\"Path\\t1-NN\")\n",
    "print(f\"{path_segm}\\t{knn_segm}\")\n",
    "print(f\"{path_segm / len(test_segm):.3f}, {knn_segm / len(test_segm):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
